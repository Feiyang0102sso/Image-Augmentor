import streamlit as st
import cv2
import os
import logging
import numpy as np
import torch
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import matplotlib.pyplot as plt
import json
from io import StringIO, BytesIO

# å¯¼å…¥æ‚¨æä¾›çš„æ¨¡å—
# ç¡®ä¿ augmentor_module.py å’Œç›¸å…³ä¾èµ–é¡¹åœ¨åŒä¸€ç›®å½•ä¸‹
from augmentor_module import ImageAugmentor

# --- åŸºæœ¬é…ç½® ---

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    # stream=st.log  # å°†æ—¥å¿—è¾“å‡ºåˆ° Streamlit ç•Œé¢
)


# --- æ¨¡å‹å’Œæ•°æ®åŠ è½½ (å¸¦ç¼“å­˜) ---

@st.cache_resource
def load_model():
    """åŠ è½½é¢„è®­ç»ƒçš„ ResNet50 æ¨¡å‹"""
    model = models.resnet50(pretrained=True)
    model.eval()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)
    return model, device


@st.cache_data
def load_imagenet_classes():
    """åŠ è½½ ImageNet ç±»åˆ«æ ‡ç­¾"""
    # å‡è®¾ imagenet_classes.txt åœ¨åŒä¸€ç›®å½•ä¸‹
    try:
        with open('imagenet_classes.txt') as f:
            classes = [line.strip() for line in f.readlines()]
        return classes
    except FileNotFoundError:
        st.error("é”™è¯¯: `imagenet_classes.txt` æ–‡ä»¶æœªæ‰¾åˆ°ã€‚è¯·ç¡®ä¿å®ƒä¸ app.py åœ¨åŒä¸€ç›®å½•ä¸‹ã€‚")
        return None


# åˆå§‹åŒ–æ¨¡å‹å’Œç±»åˆ«
model, device = load_model()
classes = load_imagenet_classes()

# å®šä¹‰ ResNet çš„é¢„å¤„ç†è½¬æ¢
preprocess = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])


# --- æ ¸å¿ƒåŠŸèƒ½å‡½æ•° (ä» augmentor_demo.py æ”¹ç¼–) ---

def load_augmentor_from_upload(uploaded_config):
    """ä»ä¸Šä¼ çš„é…ç½®æ–‡ä»¶åˆå§‹åŒ– ImageAugmentor"""
    try:
        # å°†ä¸Šä¼ çš„æ–‡ä»¶å†…å®¹è§£ç ä¸ºå­—ç¬¦ä¸²ï¼Œç„¶ååŠ è½½ä¸º JSON
        stringio = StringIO(uploaded_config.getvalue().decode("utf-8"))
        config_str = stringio.read()
        config_json = json.loads(config_str)

        # ImageAugmentor éœ€è¦ä¸€ä¸ªæ–‡ä»¶è·¯å¾„ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸´æ—¶åˆ›å»ºä¸€ä¸ª
        with open("temp_config.json", "w") as f:
            json.dump(config_json, f)

        augmentor = ImageAugmentor("temp_config.json")
        logging.info("æˆåŠŸåŠ è½½å¹¶è§£æä¸Šä¼ çš„é…ç½®æ–‡ä»¶ã€‚")
        os.remove("temp_config.json")  # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        return augmentor
    except Exception as e:
        st.error(f"åŠ è½½æˆ–è§£æé…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        logging.error(f"åŠ è½½æˆ–è§£æé…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return None


def get_pipeline_info(augmentor):
    """è·å–å¢å¼ºæµç¨‹çš„æ ‡é¢˜ä¿¡æ¯"""
    titles = []
    for op in augmentor.pipeline:
        name = op["name"]
        params = op.get("params", {})
        if name == "RandomChoice":
            choices = params.get("choices", [])
            choice_names = [c["name"] for c in choices]
            title = f"RandomChoice({', '.join(choice_names)})"
            titles.append(title)
        else:
            param_str = ", ".join(f"{k}={v}" for k, v in params.items())
            titles.append(f"{name}({param_str})" if param_str else name)
    return ["Original"] + titles


def infer_image(image_cv):
    """å¯¹å•ä¸ª OpenCV å›¾åƒè¿›è¡Œæ¨ç†"""
    if classes is None: return "æ ‡ç­¾æ–‡ä»¶ç¼ºå¤±", 0.0

    # å°† OpenCV å›¾åƒ (BGR) è½¬æ¢ä¸º PIL å›¾åƒ (RGB)
    image_rgb = cv2.cvtColor(image_cv, cv2.COLOR_BGR2RGB)
    pil_image = Image.fromarray(image_rgb)

    # åº”ç”¨é¢„å¤„ç†
    input_tensor = preprocess(pil_image)
    input_batch = input_tensor.unsqueeze(0).to(device)

    # è¿è¡Œæ¨ç†
    with torch.no_grad():
        output = model(input_batch)
        probabilities = torch.nn.functional.softmax(output[0], dim=0)

    # è·å–æœ€é«˜ç½®ä¿¡åº¦çš„é¢„æµ‹ç»“æœ
    confidence, predicted_idx = torch.max(probabilities, 0)
    predicted_class = classes[predicted_idx]

    return predicted_class, confidence.item()


def plot_and_display_results(images, augmented_images_list, titles, predictions):
    """åœ¨ Streamlit ä¸­ç»˜åˆ¶å¹¶æ˜¾ç¤ºç»“æœç½‘æ ¼"""
    num_images = len(images)
    if num_images == 0:
        st.warning("æ²¡æœ‰å¯ä¾›æ˜¾ç¤ºçš„å›¾åƒã€‚")
        return

    num_cols = len(augmented_images_list[0]) + 1

    fig = plt.figure(figsize=(5 * num_cols, 6 * num_images))

    for row_idx, (orig_img, aug_imgs) in enumerate(zip(images, augmented_images_list)):
        orig_rgb = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)

        # ç»˜åˆ¶åŸå§‹å›¾åƒ
        ax = plt.subplot(num_images, num_cols, row_idx * num_cols + 1)
        pred_text = f"{predictions[row_idx][0][0]}\n({predictions[row_idx][0][1]:.2%})"
        ax.set_title(f"{titles[0]}\n{pred_text}", fontsize=10)
        ax.axis('off')
        ax.imshow(orig_rgb)

        # ç»˜åˆ¶å¢å¼ºåçš„å›¾åƒ
        for col_idx, aug_img in enumerate(aug_imgs):
            aug_rgb = cv2.cvtColor(aug_img, cv2.COLOR_BGR2RGB)
            ax = plt.subplot(num_images, num_cols, row_idx * num_cols + col_idx + 2)
            pred_text = f"{predictions[row_idx][col_idx + 1][0]}\n({predictions[row_idx][col_idx + 1][1]:.2%})"
            ax.set_title(f"{titles[col_idx + 1]}\n{pred_text}", fontsize=10)
            ax.axis('off')
            ax.imshow(aug_rgb)

    plt.tight_layout(pad=2.0)
    st.pyplot(fig)

    # æä¾›å›¾åƒä¸‹è½½æŒ‰é’®
    buf = BytesIO()
    fig.savefig(buf, format="png", dpi=300)
    st.download_button(
        label="ä¸‹è½½ç»“æœå›¾",
        data=buf.getvalue(),
        file_name="augmentation_comparison.png",
        mime="image/png"
    )

    plt.close(fig)


def generate_report_markdown(images, titles, predictions):
    """ç”Ÿæˆ Markdown æ ¼å¼çš„æŠ¥å‘Š"""
    md_report = "## æ¨ç†æŠ¥å‘Šè¯¦æƒ…\n\n"
    for row_idx, orig_img in enumerate(images):
        md_report += f"### å›¾åƒ {row_idx + 1}\n"
        md_report += f"- **{titles[0]}**: `{predictions[row_idx][0][0]}` (ç½®ä¿¡åº¦: {predictions[row_idx][0][1]:.2%})\n"
        for col_idx in range(len(predictions[row_idx]) - 1):
            md_report += f"- **{titles[col_idx + 1]}**: `{predictions[row_idx][col_idx + 1][0]}` (ç½®ä¿¡åº¦: {predictions[row_idx][col_idx + 1][1]:.2%})\n"
        md_report += "\n"
    return md_report


# --- Streamlit UI ç•Œé¢ ---

st.set_page_config(page_title="å›¾åƒå¢å¼ºä¸æ¨ç†", layout="wide")
st.title("ğŸ–¼ï¸ å›¾åƒå¢å¼ºä¸æ¨ç†åˆ†æå™¨")
st.markdown("ä¸Šä¼ å›¾åƒå’Œé…ç½®æ–‡ä»¶ï¼Œè¿è¡Œå¢å¼ºæµç¨‹ï¼Œå¹¶è§‚å¯Ÿå…¶å¯¹æ¨¡å‹æ¨ç†ç»“æœçš„å½±å“ã€‚")

# --- ä¾§è¾¹æ  ---
st.sidebar.header("âš™ï¸ æ§åˆ¶é¢æ¿")

mode = st.sidebar.radio("é€‰æ‹©æ¨¡å¼", ('å•å¼ å›¾åƒå¤„ç†', 'æ‰¹é‡å›¾åƒå¤„ç†'))

uploaded_files = None
if mode == 'å•å¼ å›¾åƒå¤„ç†':
    uploaded_files = st.sidebar.file_uploader(
        "ä¸Šä¼ ä¸€å¼ å›¾åƒ",
        type=['png', 'jpg', 'jpeg', 'bmp', 'tif', 'tiff'],
        accept_multiple_files=False
    )
    if uploaded_files:
        uploaded_files = [uploaded_files]  # åŒ…è£…æˆåˆ—è¡¨ä»¥ç»Ÿä¸€å¤„ç†
else:
    uploaded_files = st.sidebar.file_uploader(
        "ä¸Šä¼ å¤šå¼ å›¾åƒ",
        type=['png', 'jpg', 'jpeg', 'bmp', 'tif', 'tiff'],
        accept_multiple_files=True
    )

# é…ç½®æ–‡ä»¶ä¸Šä¼ 
st.sidebar.subheader("å¢å¼ºé…ç½®")
uploaded_config = st.sidebar.file_uploader("ä¸Šä¼  config.json", type=['json'])

# æä¾›ä¸€ä¸ªé»˜è®¤çš„config.jsonç¤ºä¾‹
DEFAULT_CONFIG = """
{
  "pipeline": [
    {
      "name": "GaussianBlur",
      "params": {
        "kernel_size": 5
      },
      "prob": 1.0
    },
    {
      "name": "Rotate",
      "params": {
        "angle": 15
      },
      "prob": 1.0
    },
    {
        "name": "RandomChoice",
        "params": {
            "choices": [
                {
                    "name": "Flip",
                    "params": {"flip_code": 1}
                },
                {
                    "name": "SaltAndPepperNoise",
                    "params": {"amount": 0.05}
                }
            ]
        }
    }
  ]
}
"""
with st.sidebar.expander("æŸ¥çœ‹é»˜è®¤ config.json ç¤ºä¾‹"):
    st.code(DEFAULT_CONFIG, language='json')

# --- ä¸»é€»è¾‘ ---
if st.sidebar.button("ğŸš€ å¼€å§‹è¿è¡Œ", type="primary", use_container_width=True):
    if not uploaded_files:
        st.warning("è¯·å…ˆä¸Šä¼ è‡³å°‘ä¸€å¼ å›¾åƒã€‚")
    elif not uploaded_config:
        st.warning("è¯·ä¸Šä¼ ä¸€ä¸ª `config.json` é…ç½®æ–‡ä»¶ã€‚")
    elif classes is None:
        # é”™è¯¯å·²åœ¨ load_imagenet_classes ä¸­æ˜¾ç¤º
        pass
    else:
        with st.spinner("æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨å€™..."):
            augmentor = load_augmentor_from_upload(uploaded_config)

            if augmentor:
                titles = get_pipeline_info(augmentor)

                # ç”¨äºå­˜å‚¨æ‰€æœ‰ç»“æœçš„åˆ—è¡¨
                all_original_images = []
                all_augmented_images_list = []
                all_predictions = []

                progress_bar = st.progress(0, text="å¤„ç†è¿›åº¦")

                for i, uploaded_file in enumerate(uploaded_files):
                    # è¯»å–å’Œè½¬æ¢å›¾åƒ
                    pil_image = Image.open(uploaded_file).convert("RGB")
                    image_cv = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)

                    try:
                        # å¯¹åŸå§‹å›¾åƒè¿›è¡Œæ¨ç†
                        orig_pred, orig_conf = infer_image(image_cv)
                        logging.info(f"æ–‡ä»¶: {uploaded_file.name} | åŸå§‹å›¾åƒé¢„æµ‹: {orig_pred} ({orig_conf:.2%})")

                        # åº”ç”¨å¢å¼ºæµç¨‹å¹¶è¿›è¡Œæ¨ç†
                        augmented_images = []
                        image_predictions = [(orig_pred, orig_conf)]
                        current_image = image_cv.copy()

                        for transform in augmentor.transforms:
                            current_image = transform(current_image)
                            aug_pred, aug_conf = infer_image(current_image)
                            augmented_images.append(current_image.copy())
                            image_predictions.append((aug_pred, aug_conf))
                            logging.info(
                                f"...å¢å¼ºå ({transform.__class__.__name__}) é¢„æµ‹: {aug_pred} ({aug_conf:.2%})")

                        # ä¿å­˜ç»“æœ
                        all_original_images.append(image_cv)
                        all_augmented_images_list.append(augmented_images)
                        all_predictions.append(image_predictions)

                    except Exception as e:
                        st.error(f"å¤„ç†æ–‡ä»¶ {uploaded_file.name} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                        logging.error(f"å¤„ç†æ–‡ä»¶ {uploaded_file.name} æ—¶å‘ç”Ÿé”™è¯¯: {e}")

                    # æ›´æ–°è¿›åº¦æ¡
                    progress_bar.progress((i + 1) / len(uploaded_files), text=f"æ­£åœ¨å¤„ç†: {uploaded_file.name}")

                progress_bar.empty()

                if all_original_images:
                    st.header("ğŸ“Š å¯è§†åŒ–å¯¹æ¯”ç»“æœ")
                    plot_and_display_results(all_original_images, all_augmented_images_list, titles, all_predictions)

                    st.header("ğŸ“ æŠ¥å‘Šæ‘˜è¦")
                    md_report = generate_report_markdown(all_original_images, titles, all_predictions)
                    st.markdown(md_report)

else:
    st.info("è¯·åœ¨å·¦ä¾§ä¾§è¾¹æ ä¸­é…ç½®å‚æ•°ï¼Œç„¶åç‚¹å‡» **å¼€å§‹è¿è¡Œ**ã€‚")